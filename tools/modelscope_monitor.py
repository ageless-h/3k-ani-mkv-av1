#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é­”æ­ä»“åº“ç›‘æ§å™¨
ç›‘æ§ https://www.modelscope.cn/datasets/ageless/3k-animation-mkv-av1 ä»“åº“
å½“æ£€æµ‹åˆ°æ–°çš„å®Œæ•´æ–‡ä»¶å¤¹ä¸Šä¼ å®Œæˆæ—¶ï¼Œè‡ªåŠ¨åŠ å…¥å¤„ç†é˜Ÿåˆ—
"""

import os
import sys
import time
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Set
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from modelscope.hub.api import HubApi
    MODELSCOPE_AVAILABLE = True
except ImportError:
    MODELSCOPE_AVAILABLE = False

from config.config import Config
from src.utils import setup_logging

class ModelScopeMonitor:
    """é­”æ­ä»“åº“ç›‘æ§å™¨"""
    
    def __init__(self, token: str = None, logger=None):
        self.token = token or Config.MODELSCOPE_TOKEN
        self.logger = logger or setup_logging()
        
        if not MODELSCOPE_AVAILABLE:
            raise ImportError("è¯·å®‰è£…modelscope: pip install modelscope")
        
        # åˆå§‹åŒ–API
        self.api = HubApi()
        try:
            self.api.login(self.token)
            self.logger.info("é­”æ­APIç™»å½•æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"é­”æ­APIç™»å½•å¤±è´¥: {e}")
            raise
        
        # é…ç½®
        self.repo_id = "ageless/3k-animation-mkv-av1"
        self.monitor_interval = 300  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        self.min_folder_stable_time = 600  # æ–‡ä»¶å¤¹10åˆ†é’Ÿå†…æ— å˜åŒ–æ‰è®¤ä¸ºä¸Šä¼ å®Œæˆ
        
        # çŠ¶æ€æ–‡ä»¶
        self.state_file = "log/monitor_state.json"
        self.queue_file = "log/processing_queue.json"
        
        # åŠ è½½çŠ¶æ€
        self.last_state = self.load_state()
        self.processing_queue = self.load_queue()
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs("log", exist_ok=True)
    
    def load_state(self) -> Dict:
        """åŠ è½½ä¸Šæ¬¡çš„ä»“åº“çŠ¶æ€"""
        try:
            if os.path.exists(self.state_file):
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            self.logger.warning(f"åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        return {"folders": {}, "last_check": None}
    
    def save_state(self):
        """ä¿å­˜å½“å‰ä»“åº“çŠ¶æ€"""
        try:
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(self.last_state, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
    
    def load_queue(self) -> List[Dict]:
        """åŠ è½½å¤„ç†é˜Ÿåˆ—"""
        try:
            if os.path.exists(self.queue_file):
                with open(self.queue_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            self.logger.warning(f"åŠ è½½é˜Ÿåˆ—æ–‡ä»¶å¤±è´¥: {e}")
        return []
    
    def save_queue(self):
        """ä¿å­˜å¤„ç†é˜Ÿåˆ—"""
        try:
            with open(self.queue_file, 'w', encoding='utf-8') as f:
                json.dump(self.processing_queue, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ä¿å­˜é˜Ÿåˆ—æ–‡ä»¶å¤±è´¥: {e}")
    
    def get_repository_structure(self) -> Dict:
        """è·å–ä»“åº“çš„æ–‡ä»¶ç»“æ„"""
        try:
            self.logger.info("æ­£åœ¨è·å–ä»“åº“æ–‡ä»¶ç»“æ„...")
            
            # ä½¿ç”¨æ›´é«˜æ•ˆçš„ç­–ç•¥ï¼šåªè·å–æ–‡ä»¶åˆ—è¡¨ï¼Œä¸ä¸‹è½½å†…å®¹
            import subprocess
            cache_dir = "/tmp/monitor_cache"
            
            # æ¸…ç†æ—§ç¼“å­˜
            if os.path.exists(cache_dir):
                import shutil
                shutil.rmtree(cache_dir)
            
            # ç­–ç•¥1: å°è¯•åªä¸‹è½½å°æ–‡ä»¶æ¥è·å–ç»“æ„ä¿¡æ¯
            self.logger.info("å°è¯•ä¸‹è½½å°æ–‡ä»¶è·å–ç»“æ„ä¿¡æ¯...")
            result = subprocess.run([
                "modelscope", "download", 
                "--dataset", self.repo_id,
                "--cache_dir", cache_dir,
                "--include", "*.txt"  # åªä¸‹è½½æ–‡æœ¬æ–‡ä»¶
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode != 0:
                # ç­–ç•¥2: å°è¯•ä¸‹è½½READMEç­‰æ–‡æ¡£æ–‡ä»¶
                self.logger.info("å°è¯•ä¸‹è½½æ–‡æ¡£æ–‡ä»¶...")
                result = subprocess.run([
                    "modelscope", "download", 
                    "--dataset", self.repo_id,
                    "--cache_dir", cache_dir,
                    "--include", "README*"
                ], capture_output=True, text=True, timeout=60)
            
            if result.returncode != 0:
                # ç­–ç•¥3: ä¸æŒ‡å®šincludeï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©
                self.logger.info("å°è¯•åŸºç¡€ä¸‹è½½...")
                result = subprocess.run([
                    "modelscope", "download", 
                    "--dataset", self.repo_id,
                    "--cache_dir", cache_dir
                ], capture_output=True, text=True, timeout=300)  # å¢åŠ åˆ°5åˆ†é’Ÿ
            
            if result.returncode != 0:
                self.logger.error(f"æ‰€æœ‰ä¸‹è½½ç­–ç•¥éƒ½å¤±è´¥: {result.stderr}")
                # æœ€åçš„ç­–ç•¥ï¼šä½¿ç”¨Python SDKç›´æ¥è·å–æ–‡ä»¶åˆ—è¡¨
                return self.get_repository_structure_via_sdk()
            
            # åˆ†æä¸‹è½½çš„æ–‡ä»¶ç»“æ„
            repo_structure = {"folders": {}, "files": []}
            
            if os.path.exists(cache_dir):
                # æŸ¥æ‰¾å®é™…çš„æ•°æ®é›†ç›®å½•ï¼ˆå¯èƒ½åœ¨å­ç›®å½•ä¸­ï¼‰
                dataset_dir = cache_dir
                for root, dirs, files in os.walk(cache_dir):
                    if files:  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ…å«æ–‡ä»¶çš„ç›®å½•
                        dataset_dir = root
                        break
                
                self.logger.info(f"åˆ†ææ•°æ®é›†ç›®å½•: {dataset_dir}")
                
                for root, dirs, files in os.walk(dataset_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path, dataset_dir)
                        
                        # è·³è¿‡éšè—æ–‡ä»¶å’Œç³»ç»Ÿæ–‡ä»¶
                        if rel_path.startswith('.') or 'git' in rel_path.lower():
                            continue
                        
                        # è·å–æ–‡ä»¶ä¿¡æ¯
                        try:
                            stat = os.stat(file_path)
                            file_info = {
                                "path": rel_path,
                                "size": stat.st_size,
                                "mtime": stat.st_mtime
                            }
                            repo_structure["files"].append(file_info)
                            
                            # æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„
                            folder = os.path.dirname(rel_path)
                            if folder and folder != '.':
                                # å¤„ç†åµŒå¥—æ–‡ä»¶å¤¹è·¯å¾„
                                folder_parts = folder.split(os.sep)
                                main_folder = folder_parts[0]  # ä½¿ç”¨é¡¶çº§æ–‡ä»¶å¤¹ä½œä¸ºç³»åˆ—å
                                
                                if main_folder not in repo_structure["folders"]:
                                    repo_structure["folders"][main_folder] = {
                                        "files": [],
                                        "total_size": 0,
                                        "last_modified": 0,
                                        "file_count": 0
                                    }
                                
                                repo_structure["folders"][main_folder]["files"].append(file_info)
                                repo_structure["folders"][main_folder]["total_size"] += stat.st_size
                                repo_structure["folders"][main_folder]["last_modified"] = max(
                                    repo_structure["folders"][main_folder]["last_modified"],
                                    stat.st_mtime
                                )
                                repo_structure["folders"][main_folder]["file_count"] += 1
                        
                        except OSError:
                            continue
            
            folder_count = len(repo_structure['folders'])
            file_count = len(repo_structure['files'])
            self.logger.info(f"CLIæ–¹æ³•å‘ç° {folder_count} ä¸ªæ–‡ä»¶å¤¹, {file_count} ä¸ªæ–‡ä»¶")
            
            # å¦‚æœCLIæ–¹æ³•æ²¡æ‰¾åˆ°æœ‰æ•ˆç»“æ„ï¼Œå°è¯•SDKæ–¹æ³•
            if folder_count == 0:
                self.logger.info("CLIæ–¹æ³•æœªè·å–åˆ°æ–‡ä»¶å¤¹ç»“æ„ï¼Œå°è¯•SDKæ–¹æ³•...")
                return self.get_repository_structure_via_sdk()
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ä»¶å¤¹ä½œä¸ºè°ƒè¯•ä¿¡æ¯
            for i, (folder_name, folder_info) in enumerate(list(repo_structure['folders'].items())[:3]):
                self.logger.info(f"  ğŸ“ {folder_name}: {folder_info['file_count']} æ–‡ä»¶, {folder_info['total_size']/(1024**2):.1f} MB")
            
            return repo_structure
        
        except Exception as e:
            self.logger.error(f"è·å–ä»“åº“ç»“æ„å¤±è´¥: {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            # å°è¯•å¤‡ç”¨æ–¹æ³•
            return self.get_repository_structure_via_sdk()
    
    def get_repository_structure_via_sdk(self) -> Dict:
        """ä½¿ç”¨SDKæ–¹æ³•è·å–ä»“åº“ç»“æ„ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            self.logger.info("ä½¿ç”¨SDKæ–¹æ³•è·å–ä»“åº“ç»“æ„...")
            
            repo_structure = {"folders": {}, "files": []}
            
            # å¦‚æœé…ç½®äº†æ‰‹åŠ¨æ–‡ä»¶å¤¹åˆ—è¡¨ï¼Œä½¿ç”¨å®ƒä½œä¸ºå¤‡ç”¨
            if Config.USE_MANUAL_FOLDER_LIST and Config.MANUAL_FOLDER_LIST:
                self.logger.info("ä½¿ç”¨æ‰‹åŠ¨é…ç½®çš„æ–‡ä»¶å¤¹åˆ—è¡¨...")
                
                for folder_config in Config.MANUAL_FOLDER_LIST:
                    folder_name = folder_config["name"]
                    priority = folder_config.get("priority", 2)
                    
                    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ–‡ä»¶å¤¹ç»“æ„
                    repo_structure["folders"][folder_name] = {
                        "files": [],
                        "total_size": 1024 * 1024 * 1024,  # å‡è®¾1GB
                        "last_modified": time.time(),
                        "file_count": 10,  # å‡è®¾10ä¸ªæ–‡ä»¶
                        "priority": priority
                    }
                
                self.logger.info(f"æ‰‹åŠ¨é…ç½®åŠ è½½äº† {len(repo_structure['folders'])} ä¸ªæ–‡ä»¶å¤¹")
                return repo_structure
            
            # å¦‚æœæ²¡æœ‰æ‰‹åŠ¨é…ç½®ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
            self.logger.warning("æ²¡æœ‰æ‰‹åŠ¨é…ç½®çš„æ–‡ä»¶å¤¹åˆ—è¡¨")
            self.logger.info("å»ºè®®ï¼š")
            self.logger.info("1. åœ¨config/config.pyä¸­é…ç½®MANUAL_FOLDER_LIST")
            self.logger.info("2. æ‰‹åŠ¨æ£€æŸ¥ä»“åº“å†…å®¹")
            self.logger.info("3. æˆ–è€…ç­‰å¾…ç½‘ç»œæ”¹å–„åé‡è¯•")
            
            return repo_structure
        
        except Exception as e:
            self.logger.error(f"SDKæ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
            return {"folders": {}, "files": []}
    
    def calculate_folder_hash(self, folder_info: Dict) -> str:
        """è®¡ç®—æ–‡ä»¶å¤¹çš„hashå€¼ï¼ˆåŸºäºæ–‡ä»¶åˆ—è¡¨å’Œå¤§å°ï¼‰"""
        data = []
        for file_info in sorted(folder_info.get("files", []), key=lambda x: x["path"]):
            data.append(f"{file_info['path']}:{file_info['size']}")
        
        content = "|".join(data)
        return hashlib.md5(content.encode()).hexdigest()
    
    def detect_completed_folders(self, current_structure: Dict, force_all: bool = False) -> List[str]:
        """æ£€æµ‹å·²å®Œæˆä¸Šä¼ çš„æ–‡ä»¶å¤¹"""
        completed_folders = []
        current_time = time.time()
        
        for folder_name, folder_info in current_structure.get("folders", {}).items():
            # è·³è¿‡æ ¹ç›®å½•æ–‡ä»¶
            if not folder_name or folder_name == '.':
                continue
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨é˜Ÿåˆ—ä¸­
            already_queued = any(item["folder"] == folder_name for item in self.processing_queue)
            if already_queued:
                continue
            
            # å¦‚æœå¼ºåˆ¶æ¨¡å¼ï¼ˆåˆå§‹åŒ–æ‰«æï¼‰ï¼Œç›´æ¥æ·»åŠ æ‰€æœ‰æœ‰æ–‡ä»¶çš„æ–‡ä»¶å¤¹
            if force_all:
                if folder_info["file_count"] > 0:
                    completed_folders.append(folder_name)
                    self.logger.info(f"åˆå§‹åŒ–æ‰«æå‘ç°æ–‡ä»¶å¤¹: {folder_name} ({folder_info['file_count']} æ–‡ä»¶)")
                continue
            
            # æ­£å¸¸ç›‘æ§æ¨¡å¼ï¼šæ£€æŸ¥ç¨³å®šæ€§
            # è®¡ç®—å½“å‰æ–‡ä»¶å¤¹hash
            current_hash = self.calculate_folder_hash(folder_info)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ–‡ä»¶å¤¹æˆ–æœ‰å˜åŒ–
            last_folder_info = self.last_state.get("folders", {}).get(folder_name, {})
            last_hash = last_folder_info.get("hash", "")
            last_check_time = last_folder_info.get("last_check_time", 0)
            
            # å¦‚æœæ–‡ä»¶å¤¹å†…å®¹æœ‰å˜åŒ–ï¼Œæ›´æ–°æ£€æŸ¥æ—¶é—´
            if current_hash != last_hash:
                self.last_state.setdefault("folders", {})[folder_name] = {
                    "hash": current_hash,
                    "last_check_time": current_time,
                    "file_count": folder_info["file_count"],
                    "total_size": folder_info["total_size"],
                    "last_modified": folder_info["last_modified"]
                }
                self.logger.info(f"æ–‡ä»¶å¤¹æœ‰æ›´æ–°: {folder_name} ({folder_info['file_count']} æ–‡ä»¶)")
                continue
            
            # å¦‚æœæ–‡ä»¶å¤¹å†…å®¹ç¨³å®šè¶…è¿‡é˜ˆå€¼æ—¶é—´ï¼Œè®¤ä¸ºä¸Šä¼ å®Œæˆ
            if current_time - last_check_time >= self.min_folder_stable_time:
                if folder_info["file_count"] > 0:
                    completed_folders.append(folder_name)
                    self.logger.info(f"æ£€æµ‹åˆ°å®Œæˆçš„æ–‡ä»¶å¤¹: {folder_name}")
        
        return completed_folders
    
    def add_to_queue(self, folder_name: str, folder_info: Dict):
        """å°†æ–‡ä»¶å¤¹æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—"""
        queue_item = {
            "folder": folder_name,
            "file_count": folder_info["file_count"],
            "total_size": folder_info["total_size"],
            "added_time": datetime.now().isoformat(),
            "status": "pending",
            "priority": self.calculate_priority(folder_info)
        }
        
        self.processing_queue.append(queue_item)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆå°æ–‡ä»¶å¤¹ä¼˜å…ˆï¼‰
        self.processing_queue.sort(key=lambda x: x["priority"])
        
        self.save_queue()
        self.logger.info(f"æ–‡ä»¶å¤¹å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—: {folder_name} "
                        f"({folder_info['file_count']} æ–‡ä»¶, {folder_info['total_size']/(1024**3):.2f} GB)")
    
    def calculate_priority(self, folder_info: Dict) -> int:
        """è®¡ç®—å¤„ç†ä¼˜å…ˆçº§ï¼ˆæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰"""
        # åŸºäºæ–‡ä»¶æ•°é‡å’Œå¤§å°è®¡ç®—ä¼˜å…ˆçº§
        file_count = folder_info["file_count"]
        total_size_gb = folder_info["total_size"] / (1024**3)
        
        # å°æ–‡ä»¶å¤¹ä¼˜å…ˆ
        if file_count <= 10 and total_size_gb <= 5:
            return 1  # é«˜ä¼˜å…ˆçº§
        elif file_count <= 50 and total_size_gb <= 20:
            return 2  # ä¸­ä¼˜å…ˆçº§
        else:
            return 3  # ä½ä¼˜å…ˆçº§
    
    def get_pending_queue(self) -> List[Dict]:
        """è·å–å¾…å¤„ç†çš„é˜Ÿåˆ—é¡¹ç›®"""
        return [item for item in self.processing_queue if item["status"] == "pending"]
    
    def mark_as_processing(self, folder_name: str):
        """æ ‡è®°æ–‡ä»¶å¤¹ä¸ºå¤„ç†ä¸­"""
        for item in self.processing_queue:
            if item["folder"] == folder_name:
                item["status"] = "processing"
                item["start_time"] = datetime.now().isoformat()
                break
        self.save_queue()
    
    def mark_as_completed(self, folder_name: str, success: bool = True):
        """æ ‡è®°æ–‡ä»¶å¤¹å¤„ç†å®Œæˆ"""
        for item in self.processing_queue:
            if item["folder"] == folder_name:
                item["status"] = "completed" if success else "failed"
                item["end_time"] = datetime.now().isoformat()
                break
        self.save_queue()
    
    def monitor_once(self, force_all: bool = False) -> int:
        """æ‰§è¡Œä¸€æ¬¡ç›‘æ§æ£€æŸ¥"""
        try:
            if force_all:
                self.logger.info("å¼€å§‹åˆå§‹åŒ–æ‰«æï¼Œå°†æ‰€æœ‰ç°æœ‰æ–‡ä»¶å¤¹åŠ å…¥é˜Ÿåˆ—...")
            else:
                self.logger.info("å¼€å§‹ç›‘æ§æ£€æŸ¥...")
            
            # è·å–å½“å‰ä»“åº“ç»“æ„
            current_structure = self.get_repository_structure()
            if not current_structure:
                self.logger.warning("æ— æ³•è·å–ä»“åº“ç»“æ„")
                return 0
            
            # æ£€æµ‹å®Œæˆçš„æ–‡ä»¶å¤¹
            completed_folders = self.detect_completed_folders(current_structure, force_all)
            
            # æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
            for folder_name in completed_folders:
                folder_info = current_structure["folders"][folder_name]
                self.add_to_queue(folder_name, folder_info)
            
            # æ›´æ–°æ£€æŸ¥æ—¶é—´
            self.last_state["last_check"] = datetime.now().isoformat()
            self.save_state()
            
            # æ˜¾ç¤ºé˜Ÿåˆ—çŠ¶æ€
            pending_count = len(self.get_pending_queue())
            if pending_count > 0:
                self.logger.info(f"å½“å‰å¾…å¤„ç†é˜Ÿåˆ—: {pending_count} ä¸ªæ–‡ä»¶å¤¹")
            
            return len(completed_folders)
        
        except Exception as e:
            self.logger.error(f"ç›‘æ§æ£€æŸ¥å¤±è´¥: {e}")
            return 0
    
    def initialize_queue_from_existing(self) -> int:
        """åˆå§‹åŒ–é˜Ÿåˆ—ï¼šæ‰«æç°æœ‰æ•°æ®å¹¶å…¨éƒ¨åŠ å…¥é˜Ÿåˆ—"""
        self.logger.info("æ­£åœ¨æ‰§è¡Œåˆå§‹åŒ–æ‰«æï¼Œå°†ç°æœ‰æ‰€æœ‰æ–‡ä»¶å¤¹åŠ å…¥å¤„ç†é˜Ÿåˆ—...")
        return self.monitor_once(force_all=True)
    
    def run_monitor(self):
        """è¿è¡ŒæŒç»­ç›‘æ§"""
        self.logger.info(f"å¼€å§‹ç›‘æ§é­”æ­ä»“åº“: {self.repo_id}")
        self.logger.info(f"ç›‘æ§é—´éš”: {self.monitor_interval} ç§’")
        self.logger.info(f"ç¨³å®šæ—¶é—´é˜ˆå€¼: {self.min_folder_stable_time} ç§’")
        
        try:
            while True:
                new_folders = self.monitor_once()
                
                if new_folders > 0:
                    self.logger.info(f"æœ¬æ¬¡æ£€æŸ¥å‘ç° {new_folders} ä¸ªæ–°å®Œæˆçš„æ–‡ä»¶å¤¹")
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                self.logger.debug(f"ç­‰å¾… {self.monitor_interval} ç§’åè¿›è¡Œä¸‹æ¬¡æ£€æŸ¥...")
                time.sleep(self.monitor_interval)
        
        except KeyboardInterrupt:
            self.logger.info("ç›‘æ§å·²åœæ­¢")
        except Exception as e:
            self.logger.error(f"ç›‘æ§è¿è¡Œå¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é­”æ­ä»“åº“ç›‘æ§å™¨")
    parser.add_argument('--once', action='store_true', help='åªæ‰§è¡Œä¸€æ¬¡æ£€æŸ¥')
    parser.add_argument('--queue', action='store_true', help='æ˜¾ç¤ºå½“å‰é˜Ÿåˆ—çŠ¶æ€')
    parser.add_argument('--interval', type=int, default=300, help='ç›‘æ§é—´éš”(ç§’)')
    parser.add_argument('--init', action='store_true', help='åˆå§‹åŒ–æ¨¡å¼ï¼šæ‰«æç°æœ‰æ•°æ®å¹¶å…¨éƒ¨åŠ å…¥é˜Ÿåˆ—')
    parser.add_argument('--auto', action='store_true', help='è‡ªåŠ¨æ¨¡å¼ï¼šå…ˆåˆå§‹åŒ–å†æŒç»­ç›‘æ§')
    
    args = parser.parse_args()
    
    try:
        monitor = ModelScopeMonitor()
        monitor.monitor_interval = args.interval
        
        if args.queue:
            # æ˜¾ç¤ºé˜Ÿåˆ—çŠ¶æ€
            pending = monitor.get_pending_queue()
            print(f"ğŸ“‹ å½“å‰å¾…å¤„ç†é˜Ÿåˆ—: {len(pending)} ä¸ªæ–‡ä»¶å¤¹")
            for item in pending:
                print(f"  ğŸ“ {item['folder']} - {item['file_count']} æ–‡ä»¶ "
                     f"({item['total_size']/(1024**3):.2f} GB) "
                     f"[ä¼˜å…ˆçº§: {item['priority']}]")
        
        elif args.init:
            # åˆå§‹åŒ–æ¨¡å¼ï¼šæ‰«æç°æœ‰æ•°æ®
            new_folders = monitor.initialize_queue_from_existing()
            print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œå°† {new_folders} ä¸ªç°æœ‰æ–‡ä»¶å¤¹åŠ å…¥é˜Ÿåˆ—")
        
        elif args.once:
            # åªæ‰§è¡Œä¸€æ¬¡æ£€æŸ¥
            new_folders = monitor.monitor_once()
            print(f"âœ… æ£€æŸ¥å®Œæˆï¼Œå‘ç° {new_folders} ä¸ªæ–°å®Œæˆçš„æ–‡ä»¶å¤¹")
        
        elif args.auto:
            # è‡ªåŠ¨æ¨¡å¼ï¼šå…ˆåˆå§‹åŒ–å†ç›‘æ§
            print("ğŸš€ è‡ªåŠ¨æ¨¡å¼å¯åŠ¨")
            
            # æ­¥éª¤1ï¼šåˆå§‹åŒ–æ‰«æ
            new_folders = monitor.initialize_queue_from_existing()
            print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œå°† {new_folders} ä¸ªç°æœ‰æ–‡ä»¶å¤¹åŠ å…¥é˜Ÿåˆ—")
            
            # æ­¥éª¤2ï¼šæŒç»­ç›‘æ§
            print("ğŸ“¡ å¼€å§‹æŒç»­ç›‘æ§æ–°ä¸Šä¼ çš„æ–‡ä»¶...")
            monitor.run_monitor()
        
        else:
            # æŒç»­ç›‘æ§
            monitor.run_monitor()
    
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        return 1

if __name__ == "__main__":
    exit(main()) 